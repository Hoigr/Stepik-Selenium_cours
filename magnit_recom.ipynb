{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xhWFEbMs-qNE8jFTcZsJ84VJZds7WYbG",
      "authorship_tag": "ABX9TyMfvzlp/Ynn2CCaFRcK7DE2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hoigr/Stepik-Selenium_cours/blob/main/magnit_recom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "соревнования https://www.kaggle.com/competitions/recsys-in-practice/overview\n",
        "\n",
        "базлайн https://colab.research.google.com/drive/1NGkBgCN7h2hMgNYtdOyirDxoZUE-Sm7g?usp=sharing\n",
        "\n",
        "дата https://goldberg.berkeley.edu/jester-data/"
      ],
      "metadata": {
        "id": "ASpfOz_XZU5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "!pip install \"scikit-surprise==1.1.3\"\n",
        "!pip install optuna\n",
        "#!pip install joblib\n",
        "#!pip install -U lightautoml"
      ],
      "metadata": {
        "id": "sVu-BDBQdtoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import sqrt\n",
        "\n",
        "import scipy.sparse as sparse\n",
        "import pickle\n",
        "import joblib\n",
        "\n",
        "#import optuna #https://habr.com/ru/articles/704432/\n",
        "\n",
        "import catboost as cb\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "from surprise import Dataset, AlgoBase, Reader, KNNWithMeans, accuracy, SVDpp, CoClustering\n",
        "from surprise.model_selection import GridSearchCV\n",
        "from surprise.model_selection import KFold\n",
        "from surprise.model_selection import train_test_split as tts\n",
        "\n",
        "#from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
        "#from lightautoml.tasks import Task\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.metrics import RootMeanSquaredError as RMSE\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, BatchNormalization, LSTM, Dropout, Input\n",
        "from keras.models import load_model\n",
        "from tensorflow.python.keras import backend as K\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "#import torch\n"
      ],
      "metadata": {
        "id": "kWN9TdU2dRzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ha2csBsnZJ8H"
      },
      "outputs": [],
      "source": [
        "class Data:\n",
        "    def __init__(self, train:str, test:str, submit:str, full:str, gpu:bool=False):\n",
        "        self.url = {'train':train, 'test':test, 'submit':submit, 'full':full}\n",
        "        self.seed = 42\n",
        "        self.train = pd.read_csv(train)\n",
        "        self.test = pd.read_csv(test)\n",
        "        self.full = pd.read_csv(full)\n",
        "        self.submit = pd.read_csv(submit)\n",
        "        self.uid_items = None\n",
        "        self.jid_items = None\n",
        "        self.cslr = None\n",
        "        self.gpu = gpu\n",
        "        self.implict_bpr = None\n",
        "        self.implict_als = None\n",
        "        self.implict_lmf = None\n",
        "        self.gsKNN = None\n",
        "        self.gsSVD = None\n",
        "        self.gsCC = None\n",
        "        self.algo = {'KNN':None, 'SVD':None, 'CC':None}\n",
        "        self.automl = None\n",
        "        self.learner = None\n",
        "        self.catb = None\n",
        "        self.kerasm = None\n",
        "        self.ans = None\n",
        "        \n",
        "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.full[['UID', 'JID']],\n",
        "                                                                                self.full['Rating'],\n",
        "                                                                                test_size=0.2,\n",
        "                                                                                random_state=self.seed)\n",
        "\n",
        "    def metric(self):\n",
        "        for i in self.train.columns:\n",
        "            if i not in ('UID', 'JID', 'Rating'):\n",
        "                print(f'RMSE {i}: {sqrt(mse(self.train[\"Rating\"], self.train[i]))}')\n",
        "\n",
        "    def load_cat(self, cat:str):\n",
        "        mode = 'GPU' if self.gpu else 'CPU'\n",
        "        self.catb = CatBoostRegressor(iterations=1000,\n",
        "                                    learning_rate=0.1,\n",
        "                                    loss_function='RMSE',\n",
        "                                    task_type=mode,\n",
        "                                    random_seed=self.seed)\n",
        "        self.catb.load_model(cat)\n",
        "\n",
        "    def load_gscv(self, knn:str, svd:str, cc:str):\n",
        "        with open(knn, 'rb') as file:\n",
        "            self.algo['KNN'] = pickle.load(file)\n",
        "        with open(svd, 'rb') as file:\n",
        "            self.algo['SVD'] = pickle.load(file)\n",
        "        with open(cc, 'rb') as file:\n",
        "            self.algo['CC'] = pickle.load(file)\n",
        "\n",
        "    def load_lama(self, lama:str):\n",
        "        self.automl = joblib.load(lama)\n",
        "\n",
        "    def load_keras(self, ker:str):\n",
        "        self.kerasm = load_model(ker)\n",
        "\n",
        "    def load_ans(self, ans:str):\n",
        "        self.ans = joblib.load(ans)\n",
        "\n",
        "    def load_data(self, train, test, submit):\n",
        "        self.train = pd.read_csv(train)\n",
        "        self.test = pd.read_csv(test)\n",
        "        self.submit = pd.read_csv(submit)\n",
        "\n",
        "    def save_train_test(self):\n",
        "        temp = ''\n",
        "        for i in self.train.columns:\n",
        "            if i not in ('Rating', 'UID', 'JID'):\n",
        "                temp += i[0].upper()\n",
        "        self.train.to_csv(r'/content/drive/MyDrive/DATA/MAGNIT/TT/train_predict'+temp+r'.csv')\n",
        "        self.test.to_csv(r'/content/drive/MyDrive/DATA/MAGNIT/TT/test_predict'+temp+r'.csv')\n",
        "\n",
        "    def save_submit(self):\n",
        "        temp = ''\n",
        "        for i in self.train.columns:\n",
        "            if i not in ('Rating', 'UID', 'JID'):\n",
        "                temp += i[0].upper()\n",
        "        self.submit.to_csv(r'/content/drive/MyDrive/DATA/MAGNIT/out'+temp+r'.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(Data):\n",
        "\n",
        "    def cat(self, save=False):\n",
        "        categorical_column = ['UID', 'JID']\n",
        "        mode = 'GPU' if self.gpu else 'CPU'\n",
        "        self.catb = CatBoostRegressor(iterations=1000, task_type=mode, verbose=True)\n",
        "\n",
        "        self.catb.fit(self.x_train,\n",
        "                    self.y_train,\n",
        "                    eval_set=(self.x_test, self.y_test),\n",
        "                    cat_features=categorical_column\n",
        "            )\n",
        "        \n",
        "        self.train['cat'] = self.catb.predict(self.train[['UID', 'JID']])\n",
        "        self.test['cat'] = self.catb.predict(self.test[['UID', 'JID']])\n",
        "        print(f'CATBOOST RMSE : {sqrt(mse(self.train[\"Rating\"], self.train[\"cat\"]))}')\n",
        "\n",
        "        if save == True:\n",
        "            self.catb.save_model(r'/content/drive/MyDrive/DATA/MAGNIT/model/cat.cbm',\n",
        "                                format=\"cbm\",\n",
        "                                export_parameters=None,\n",
        "                                pool=None)                             \n",
        "\n",
        "    def lama(self, save:bool=False):\n",
        "\n",
        "        train, valid = train_test_split(self.train[['UID', 'JID', 'Rating']], \n",
        "                                        test_size=0.2,\n",
        "                                        )\n",
        "        self.automl = TabularAutoML(\n",
        "                        task = Task(name = 'reg',\n",
        "                        metric = lambda y_true, y_pred: sqrt(mse(y_true, y_pred)))\n",
        "                            )\n",
        "        oof_pred = self.automl.fit_predict(train, \n",
        "                                      valid_data=valid, \n",
        "                                      roles = {'target': 'Rating'}\n",
        "                                      )\n",
        "        \n",
        "        self.train['lama'] = self.automl.predict(self.train[['UID', 'JID']]).data[:,0]\n",
        "        self.test['lama'] = self.automl.predict(self.test[['UID', 'JID']]).data[:,0]\n",
        "        print(f'LAMA RMSE : {sqrt(mse(self.train[\"Rating\"], self.train[\"lama\"]))}')\n",
        "        if save == True:\n",
        "            joblib.dump(self.automl, r'/content/drive/MyDrive/DATA/MAGNIT/model/lama.joblib')\n",
        "\n",
        "    def gscv(self, save:bool=False):\n",
        "        reader = Reader(rating_scale=(-10, 10))\n",
        "        data = Dataset.load_from_df(self.full[['UID', 'JID', 'Rating']], reader)\n",
        "        trainset, testset = tts(data, test_size=0.2, random_state=self.seed)\n",
        "        \n",
        "        def KNN(data, trainset, testset):\n",
        "            print('Метод KNN')\n",
        "            sim_options = {\n",
        "                            \"name\": [\"msd\", \"cosine\"], # способы оценки похожести (в GridSearch)\n",
        "                            \"min_support\": [3, 4],     # минимальное кол-во общих пользоватлей с данной шуткой\n",
        "                            \"user_based\": [False],     # поиск \"похожести\" будет на основе шуток, а не пользователей\n",
        "                            }\n",
        "\n",
        "            param_grid = {\"sim_options\": sim_options}\n",
        "            self.gsKNN = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"], cv=2,)\n",
        "            self.gsKNN.fit(data)\n",
        "\n",
        "            algo = self.gsKNN.best_estimator['rmse']\n",
        "            algo.fit(trainset)\n",
        "            self.algo['KNN'] = algo\n",
        "            self.train['gsKNN'] = self.train[['UID', 'JID']].apply(lambda x: algo.predict(x[0], x[1], verbose=False).est,\n",
        "                                                        axis = 1)\n",
        "            \n",
        "            self.test['gsKNN'] = self.test[['UID', 'JID']].apply(lambda x: algo.predict(x[0], x[1], verbose=False).est,\n",
        "                                                        axis = 1)\n",
        "            print('Метод KNN OK\\n')\n",
        "\n",
        "        def SVD(data, trainset, testset):\n",
        "            print('Метод SVD++')\n",
        "            param_grid = {\n",
        "                'n_factors': [50],\n",
        "                'n_epochs': [10],\n",
        "                'lr_all': [0.005],\n",
        "                'verbose': [True],\n",
        "                'random_state': [self.seed]\n",
        "            }\n",
        "\n",
        "            self.gsSVD = GridSearchCV(SVDpp, param_grid, measures=[\"rmse\", \"mae\"], cv=2, )\n",
        "            self.gsSVD.fit(data)\n",
        "\n",
        "            algo = self.gsSVD.best_estimator['rmse']\n",
        "            algo.fit(trainset)\n",
        "            self.algo['SVD'] = algo\n",
        "            if save == True:\n",
        "                with open(r'/content/drive/MyDrive/DATA/MAGNIT/model/gsSVD.pickle', 'wb') as file:\n",
        "                    pickle.dump(algo, file)\n",
        "\n",
        "            self.train['gsSVD'] = self.train[['UID', 'JID']].apply(lambda x: algo.predict(x[0], x[1], verbose=False).est,\n",
        "                                                        axis = 1)\n",
        "            \n",
        "            self.test['gsSVD'] = self.test[['UID', 'JID']].apply(lambda x: algo.predict(x[0], x[1], verbose=False).est,\n",
        "                                                        axis = 1)\n",
        "            print('Метод SVD++ OK\\n')\n",
        "\n",
        "        def co_cluster(data, trainset, testset):\n",
        "            print('Метод Co-clustering')\n",
        "            param_grid = {\n",
        "                'n_cltr_u': [50],\n",
        "                'n_cltr_i': [50], \n",
        "                'n_epochs': [20],\n",
        "                'random_state': [self.seed],\n",
        "                'verbose':[True]\n",
        "            }\n",
        "            self.gsCC = GridSearchCV(CoClustering, param_grid, measures=[\"rmse\", \"mae\"], cv=2, )\n",
        "            self.gsCC.fit(data)\n",
        "            algo = self.gsCC.best_estimator['rmse']\n",
        "            algo.fit(trainset)\n",
        "            self.algo['CC'] = algo\n",
        "            self.train['gsCC'] = self.train[['UID', 'JID']].apply(lambda x: algo.predict(x[0], x[1], verbose=False).est,\n",
        "                                                        axis = 1)\n",
        "            \n",
        "            self.test['gsCC'] = self.test[['UID', 'JID']].apply(lambda x: algo.predict(x[0], x[1], verbose=False).est,\n",
        "                                                        axis = 1)\n",
        "            print('Метод Co-clustering OK\\n')\n",
        "\n",
        "        KNN(data=data, trainset=trainset, testset=testset)\n",
        "        SVD(data=data, trainset=trainset, testset=testset)\n",
        "        co_cluster(data=data, trainset=trainset, testset=testset)\n",
        "        print('KNN RMSE =', self.gsKNN.best_score[\"rmse\"])\n",
        "        print('SVD++ RMSE =', self.gsSVD.best_score[\"rmse\"])\n",
        "        print('Co-clustering RMSE =', self.gsCC.best_score[\"rmse\"])\n",
        "\n",
        "        if save == True:\n",
        "            with open(r'/content/drive/MyDrive/DATA/MAGNIT/model/gsKNN.pickle', 'wb') as file:\n",
        "                pickle.dump(self.algo['KNN'], file)\n",
        "            with open(r'/content/drive/MyDrive/DATA/MAGNIT/model/gsSVD.pickle', 'wb') as file:\n",
        "                pickle.dump(self.algo['SVD'], file)\n",
        "            with open(r'/content/drive/MyDrive/DATA/MAGNIT/model/gsCC.pickle', 'wb') as file:\n",
        "                pickle.dump(self.algo['CC'], file)\n",
        "\n",
        "    def NN(self, save:bool=False):\n",
        "\n",
        "        self.kerasm = keras.Sequential()\n",
        "        self.kerasm.add(Dense(2, activation='linear'))\n",
        "        self.kerasm.add(Dense(100, activation='tanh'))\n",
        "        self.kerasm.add(Dense(100, activation='tanh'))\n",
        "        self.kerasm.add(Dense(1, activation='linear'))\n",
        "\n",
        "\n",
        "        self.kerasm.compile(optimizer='adam', \n",
        "                            loss = 'MSE',\n",
        "                            metrics = [RMSE()])\n",
        "        \n",
        "        self.kerasm.fit(self.x_train[['UID', 'JID']], self.y_train, epochs=3)\n",
        "        self.train['keras'] = self.kerasm.predict(self.train[['UID', 'JID']])\n",
        "        self.test['keras'] = self.kerasm.predict(self.test[['UID', 'JID']])\n",
        "        print(f'KERAS RMSE : {sqrt(mse(self.train[\"Rating\"], self.train[\"keras\"]))}')\n",
        "        if save == True:\n",
        "            self.kerasm.save(r'/content/drive/MyDrive/DATA/MAGNIT/model/keras.h5')\n",
        "\n",
        "    def predict_data(self, alg:tuple):\n",
        "        for i in alg:\n",
        "            if i == 'cat':\n",
        "                self.train['cat'] = self.catb.predict(self.train[['UID', 'JID']])\n",
        "                self.test['cat'] = self.catb.predict(self.test[['UID', 'JID']])\n",
        "                self.x_train['cat'] = self.catb.predict(self.x_train[['UID', 'JID']])\n",
        "                self.x_test['cat'] = self.catb.predict(self.x_test[['UID', 'JID']])\n",
        "            elif i == 'gscv':\n",
        "                self.train['gsKNN'] = self.train[['UID', 'JID']].apply(lambda x: self.algo['KNN'].predict(x[0], x[1], verbose=False).est, axis = 1)\n",
        "                self.test['gsKNN'] = self.test[['UID', 'JID']].apply(lambda x: self.algo['KNN'].predict(x[0], x[1], verbose=False).est, axis = 1)\n",
        "\n",
        "                self.train['gsSVD'] = self.train[['UID', 'JID']].apply(lambda x: self.algo['SVD'].predict(x[0], x[1], verbose=False).est, axis = 1)\n",
        "                self.test['gsSVD'] = self.test[['UID', 'JID']].apply(lambda x: self.algo['SVD'].predict(x[0], x[1], verbose=False).est, axis = 1)\n",
        "\n",
        "                self.train['gsCC'] = self.train[['UID', 'JID']].apply(lambda x: self.algo['CC'].predict(x[0], x[1], verbose=False).est, axis = 1)\n",
        "                self.test['gsCC'] = self.test[['UID', 'JID']].apply(lambda x: self.algo['CC'].predict(x[0], x[1], verbose=False).est, axis = 1)\n",
        "            elif i == 'lama':\n",
        "\n",
        "                self.train['lama'] = self.automl.predict(self.train[['UID', 'JID', 'Rating']]).data[:,0]\n",
        "                self.test['lama'] = self.automl.predict(self.test[['UID', 'JID', 'Rating']]).data[:,0]\n",
        "            elif i == 'keras':\n",
        "                self.train['keras'] = self.kerasm.predict(self.train[['UID', 'JID']])\n",
        "                self.test['keras'] = self.kerasm.predict(self.test[['UID', 'JID']])\n",
        "            elif i == 'ans':\n",
        "                test_col = list(self.train.columns)\n",
        "                test_col.remove('UID')\n",
        "                test_col.remove('JID')\n",
        "                test_col.remove('InteractionID')\n",
        "                train_col = list(self.train.columns)\n",
        "                train_col.remove('UID')\n",
        "                train_col.remove('JID')                \n",
        "                train_col.remove('Rating')\n",
        "                self.train['lama'] = self.ans.predict(self.train[train_col]).data[:,0]\n",
        "                self.test['lama'] = self.ans.predict(self.test[test_col]).data[:,0]\n",
        "            else:\n",
        "                print(i, 'Некоректное имя модели')\n",
        "\n",
        "    def cat_ans(self, save:bool=False):\n",
        "        mode = 'GPU' if self.gpu else 'CPU'\n",
        "        self.ansm = CatBoostRegressor(iterations=10, task_type=mode, verbose=True)\n",
        "        col_train = ['gsKNN', 'gsSVD', 'gsCC']\n",
        "        x_train, x_test, y_train, y_test = train_test_split(self.train[col_train],\n",
        "                                                            self.train['Rating'],\n",
        "                                                            test_size=0.2,\n",
        "                                                            random_state=self.seed)\n",
        "\n",
        "        self.ansm.fit(self.x_train,\n",
        "                self.y_train,\n",
        "                eval_set=(self.x_test, self.y_test),\n",
        "            )\n",
        "\n",
        "        self.train['an'] = self.ansm.predict(self.train[['gsKNN', 'gsSVD', 'gsCC']])\n",
        "        #self.test['an'] = self.ansm.predict(self.test[col_train])\n",
        "        #self.submit['Rating'] = self.test['an']\n",
        "        print(f'CATBOOST ANS RMSE : {sqrt(mse(self.train[\"Rating\"], self.train[\"an\"]))}')\n",
        "        if save == True:\n",
        "            self.ansm.save_model(r'/content/drive/MyDrive/DATA/MAGNIT/model/ans.cbm',\n",
        "                                format=\"cbm\",\n",
        "                                export_parameters=None,\n",
        "                                pool=None)\n",
        "            \n",
        "    def ansib(self, save:bool=False):\n",
        "        train_col = list(self.train.columns)\n",
        "        train_col.remove('UID')\n",
        "        train_col.remove('JID')\n",
        "        test_col = list(self.test.columns)\n",
        "        test_col.remove('InteractionID')\n",
        "        test_col.remove('UID')\n",
        "        test_col.remove('JID')\n",
        "        print(train_col)\n",
        "        print(test_col)\n",
        "\n",
        "        train, valid = train_test_split(self.train, \n",
        "                                        test_size=0.2,\n",
        "                                        )\n",
        "        self.ans = TabularAutoML(\n",
        "                        task = Task(name = 'reg',\n",
        "                        metric = lambda y_true, y_pred: sqrt(mse(y_true, y_pred)))\n",
        "                            )\n",
        "        oof_pred = self.ans.fit_predict(train, \n",
        "                                      valid_data=valid, \n",
        "                                      roles = {'target': 'Rating'}\n",
        "                                      )\n",
        "        \n",
        "        self.train['ans'] = self.ans.predict(self.train[train_col]).data[:,0]\n",
        "        self.test['ans'] = self.ans.predict(self.test[test_col]).data[:,0]\n",
        "        self.submit['Rating'] = self.test['ans']\n",
        "        if save == True:\n",
        "            joblib.dump(self.ans, r'/content/drive/MyDrive/DATA/MAGNIT/model/ansib.joblib')\n",
        "\n",
        "    def fin(self):\n",
        "        # categorical_column = ['UID', 'JID']\n",
        "        # cat_features=categorical_column\n",
        "        model = CatBoostRegressor(iterations=1000, verbose=True)\n",
        "        col_train = ['gsKNN', 'gsSVD', 'gsCC', 'cat']\n",
        "        col_test = ['gsKNN', 'gsSVD', 'gsCC', 'cat']\n",
        "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.train[col_train],\n",
        "                                                                                self.train['Rating'],\n",
        "                                                                                test_size=0.2,\n",
        "                                                                                random_state=self.seed)                    \n",
        "        model.fit(self.x_train,\n",
        "                    self.y_train,\n",
        "                    eval_set=(self.x_test, self.y_test),\n",
        "                    \n",
        "            )\n",
        "        self.train['fin'] = model.predict(self.train[col_train])\n",
        "        self.test['fin'] = model.predict(self.test[col_test])\n",
        "        self.submit['Rating'] = self.test['fin']       "
      ],
      "metadata": {
        "id": "MtARu4UDeJww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data = r'/content/drive/MyDrive/DATA/MAGNIT/jester_ratings.csv'\n",
        "train = r'/content/drive/MyDrive/DATA/MAGNIT/train_joke_df.csv'\n",
        "test = r'/content/drive/MyDrive/DATA/MAGNIT/test_joke_df_nofactrating.csv'\n",
        "submit = r'/content/drive/MyDrive/DATA/MAGNIT/sample_submission.csv'\n",
        "gpu = False\n",
        "zn = Model(train=train, test=test, submit=submit, full=full_data, gpu=gpu)\n",
        "%time zn.gscv(save=False) # длительность ~ 15 минут + 13 минут + 13 минут CPU\n",
        "zn.save_train_test()\n",
        "%time zn.cat(save=False) # длительность ~ 8 минут CPU/GPU\n",
        "zn.save_train_test()\n",
        "%time zn.fin()\n",
        "#%time zn.lama(save=False) # длительность ~ 30 минут CPU\n",
        "#zn.save_train_test()\n",
        "#%time zn.NN(save=False) # длительность ~ 30 минут CPU\n",
        "#zn.save_train_test()\n",
        "#%time zn.cat_ans(save=False) \n",
        "zn.metric()\n",
        "zn.save_train_test()\n",
        "zn.save_submit()"
      ],
      "metadata": {
        "id": "jnxArNffeHkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zn.test"
      ],
      "metadata": {
        "id": "t5bZNqwNVjar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = r'/content/drive/MyDrive/DATA/MAGNIT/TT/train_predictGGGC.csv'\n",
        "test = r'/content/drive/MyDrive/DATA/MAGNIT/TT/test_predictGGGC.csv'\n",
        "submit = r'/content/drive/MyDrive/DATA/MAGNIT/sample_submission.csv'\n",
        "gpu = False\n",
        "zn = Model(train=train, test=test, submit=submit, gpu=gpu)\n",
        "zn.train = zn.train.drop(['Unnamed: 0'], axis=1)\n",
        "zn.test = zn.test.drop(['Unnamed: 0'], axis=1)\n",
        "zn.fin()\n",
        "zn.metric()\n",
        "zn.save_submit()"
      ],
      "metadata": {
        "id": "z5QWWV4-oHlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data = r'/content/drive/MyDrive/DATA/MAGNIT/jester_ratings.csv'\n",
        "train = r'/content/drive/MyDrive/DATA/MAGNIT/train_joke_df.csv'\n",
        "test = r'/content/drive/MyDrive/DATA/MAGNIT/test_joke_df_nofactrating.csv'\n",
        "submit = r'/content/drive/MyDrive/DATA/MAGNIT/sample_submission.csv'\n",
        "gpu = False\n",
        "zn = Model(train=train, test=test, submit=submit, gpu=gpu)\n",
        "# Загрузка модели Surprise\n",
        "url_knn = r'/content/drive/MyDrive/DATA/MAGNIT/model/gsKNN.pickle'\n",
        "url_svd = r'/content/drive/MyDrive/DATA/MAGNIT/model/gsSVD.pickle'\n",
        "url_cc = r'/content/drive/MyDrive/DATA/MAGNIT/model/gsCC.pickle'\n",
        "zn.load_gscv(knn=url_knn, svd=url_svd, cc=url_cc)\n",
        "url_cat = r'/content/drive/MyDrive/DATA/MAGNIT/model/cat.cbm'\n",
        "zn.load_cat(cat=url_cat)\n",
        "zn.predict_data(('gscv','cat'))\n",
        "#%time zn.NN(save=True)\n",
        "%time zn.cat_ans(save=True) \n",
        "zn.save_train_test()\n",
        "zn.metric()\n",
        "zn.save_submit()"
      ],
      "metadata": {
        "id": "XkYFOvXgHj6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_knn = r'/content/drive/MyDrive/DATA/MAGNIT/model/gsKNN.pickle'\n",
        "url_svd = r'/content/drive/MyDrive/DATA/MAGNIT/model/gsSVD.pickle'\n",
        "url_cc = r'/content/drive/MyDrive/DATA/MAGNIT/model/gsCC.pickle'\n",
        "zn.load_gscv(knn=url_knn, svd=url_svd, cc=url_cc)\n",
        "url_cat = r'/content/drive/MyDrive/DATA/MAGNIT/model/cat.cbm'\n",
        "zn.load_cat(cat=url_cat)\n",
        "zn.predict_data(('gscv','cat'))\n",
        "\n",
        "%time zn.cat_ans(save=True) \n",
        "zn.save_train_test()\n",
        "zn.metric()\n",
        "zn.save_submit()"
      ],
      "metadata": {
        "id": "fJSTMRrpuWQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка модели catboost\n",
        "url_cat = r'/content/drive/MyDrive/DATA/MAGNIT/model/cat.cbm'\n",
        "zn.load_cat(cat=url_cat)"
      ],
      "metadata": {
        "id": "D1ALKIp3Sj6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка модели Surprise\n",
        "url_knn = r'/content/drive/MyDrive/DATA/MAGNIT/model/gsKNN.pickle'\n",
        "url_svd = r'/content/drive/MyDrive/DATA/MAGNIT/model/gsSVD.pickle'\n",
        "url_cc = r'/content/drive/MyDrive/DATA/MAGNIT/model/gsCC.pickle'\n",
        "zn.load_gscv(knn=url_knn, svd=url_svd, cc=url_cc)"
      ],
      "metadata": {
        "id": "LLX1u4w0U0TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка модели LAMA\n",
        "# пока не работает\n",
        "# https://you.com/search?q=lama+automl+save+model&fromSearchBar=true&tbm=youchat&cid=c2_34ea8efb-e0ac-4642-ba06-9494b1a69a6a\n",
        "url_lama = r'/content/drive/MyDrive/DATA/MAGNIT/model/lama.joblib'\n",
        "zn.load_lama(lama=url_lama)"
      ],
      "metadata": {
        "id": "2Krvg3OG4g94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка модели KERAS\n",
        "url_keras = r'/content/drive/MyDrive/DATA/MAGNIT/model/keras.h5'\n",
        "zn.load_keras(ker=url_keras)"
      ],
      "metadata": {
        "id": "jY3--wSOknJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка модели ансамбля\n",
        "# пока не работает\n",
        "url_ans = r'/content/drive/MyDrive/DATA/MAGNIT/model/ans.joblib'\n",
        "zn.load_ansib(ans=url_ans)"
      ],
      "metadata": {
        "id": "SGdJkMrp2NVo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}